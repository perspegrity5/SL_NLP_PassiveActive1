{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Quality Scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the third notebook which evaluates three metrics. \n",
    "* The grading level for each clause\n",
    "* The reading ease in each clause\n",
    "* The quality of sentence for each clause.\n",
    "\n",
    "### Introduction to Grading ease and Reading Level Scoring\n",
    "Grading ease and Reading Levels are computed using the metrics elaborated here: https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textacy in /srv/conda/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already satisfied: ftfy<5.0.0,>=4.2.0 in /srv/conda/lib/python3.6/site-packages (from textacy) (4.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17.0 in /srv/conda/lib/python3.6/site-packages (from textacy) (0.20.2)\n",
      "Requirement already satisfied: python-levenshtein>=0.12.0 in /srv/conda/lib/python3.6/site-packages (from textacy) (0.12.0)\n",
      "Requirement already satisfied: unidecode>=0.04.19 in /srv/conda/lib/python3.6/site-packages (from textacy) (1.0.23)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /srv/conda/lib/python3.6/site-packages (from textacy) (3.1.0)\n",
      "Requirement already satisfied: tqdm>=4.11.1 in /srv/conda/lib/python3.6/site-packages (from textacy) (4.30.0)\n",
      "Requirement already satisfied: networkx>=1.11 in /srv/conda/lib/python3.6/site-packages (from textacy) (2.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /srv/conda/lib/python3.6/site-packages (from textacy) (1.2.0)\n",
      "Requirement already satisfied: ijson>=2.3 in /srv/conda/lib/python3.6/site-packages (from textacy) (2.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in /srv/conda/lib/python3.6/site-packages (from textacy) (1.16.1)\n",
      "Requirement already satisfied: cytoolz>=0.8.0 in /srv/conda/lib/python3.6/site-packages (from textacy) (0.9.0.1)\n",
      "Requirement already satisfied: pyemd>=0.3.0 in /srv/conda/lib/python3.6/site-packages (from textacy) (0.5.1)\n",
      "Requirement already satisfied: pyphen>=0.9.4 in /srv/conda/lib/python3.6/site-packages (from textacy) (0.9.5)\n",
      "Requirement already satisfied: requests>=2.10.0 in /srv/conda/lib/python3.6/site-packages (from textacy) (2.21.0)\n",
      "Requirement already satisfied: spacy>=2.0.0 in /srv/conda/lib/python3.6/site-packages (from textacy) (2.0.11)\n",
      "Requirement already satisfied: html5lib in /srv/conda/lib/python3.6/site-packages (from ftfy<5.0.0,>=4.2.0->textacy) (1.0.1)\n",
      "Requirement already satisfied: wcwidth in /srv/conda/lib/python3.6/site-packages (from ftfy<5.0.0,>=4.2.0->textacy) (0.1.7)\n",
      "Requirement already satisfied: setuptools in /srv/conda/lib/python3.6/site-packages (from python-levenshtein>=0.12.0->textacy) (40.7.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /srv/conda/lib/python3.6/site-packages (from networkx>=1.11->textacy) (4.3.2)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /srv/conda/lib/python3.6/site-packages (from cytoolz>=0.8.0->textacy) (0.9.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /srv/conda/lib/python3.6/site-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /srv/conda/lib/python3.6/site-packages (from requests>=2.10.0->textacy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/lib/python3.6/site-packages (from requests>=2.10.0->textacy) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /srv/conda/lib/python3.6/site-packages (from requests>=2.10.0->textacy) (1.24.1)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /srv/conda/lib/python3.6/site-packages (from spacy>=2.0.0->textacy) (0.28.0)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /srv/conda/lib/python3.6/site-packages (from spacy>=2.0.0->textacy) (1.31.2)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /srv/conda/lib/python3.6/site-packages (from spacy>=2.0.0->textacy) (1.0.1)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.1 in /srv/conda/lib/python3.6/site-packages (from spacy>=2.0.0->textacy) (6.10.3)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /srv/conda/lib/python3.6/site-packages (from spacy>=2.0.0->textacy) (0.9.6)\n",
      "Requirement already satisfied: pathlib in /srv/conda/lib/python3.6/site-packages (from spacy>=2.0.0->textacy) (1.0.1)\n",
      "Requirement already satisfied: ujson>=1.35 in /srv/conda/lib/python3.6/site-packages (from spacy>=2.0.0->textacy) (1.35)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /srv/conda/lib/python3.6/site-packages (from spacy>=2.0.0->textacy) (0.2.9)\n",
      "Requirement already satisfied: regex==2017.4.5 in /srv/conda/lib/python3.6/site-packages (from spacy>=2.0.0->textacy) (2017.4.5)\n",
      "Requirement already satisfied: webencodings in /srv/conda/lib/python3.6/site-packages (from html5lib->ftfy<5.0.0,>=4.2.0->textacy) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in /srv/conda/lib/python3.6/site-packages (from html5lib->ftfy<5.0.0,>=4.2.0->textacy) (1.12.0)\n",
      "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /srv/conda/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0->textacy) (0.6.1)\n",
      "Requirement already satisfied: msgpack-numpy<1.0.0,>=0.4.1 in /srv/conda/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0->textacy) (0.4.3.2)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /srv/conda/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0->textacy) (1.10.11)\n",
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 119.3MB/s ta 0:00:01   18% |██████                          | 6.9MB 117.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz in /srv/conda/lib/python3.6/site-packages\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /srv/conda/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "    /srv/conda/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "!pip install textacy\n",
    "!python3 -m spacy download en\n",
    "import textacy\n",
    "import pandas as pd\n",
    "from textacy.text_stats import TextStats\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input for this notebook is from \"abstraction_scored.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>prompt_number</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>clauses_text_final</th>\n",
       "      <th>voice</th>\n",
       "      <th>idx</th>\n",
       "      <th>abstraction_score</th>\n",
       "      <th>abstraction_score_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2508.27</td>\n",
       "      <td>2508</td>\n",
       "      <td>27</td>\n",
       "      <td>98</td>\n",
       "      <td>Children who step out of line</td>\n",
       "      <td>I don't know what that means (when children do...</td>\n",
       "      <td>[I don, t know, what that means, when children...</td>\n",
       "      <td>[P_bevb_x, A_def, A_def, P_bevb_x, A_def, P_be...</td>\n",
       "      <td>301</td>\n",
       "      <td>[0.22, 0.14, 0.14, 0.25, 0.14, 0.25]</td>\n",
       "      <td>[0.88, 0.56, 0.56, 1.0, 0.56, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2319.03</td>\n",
       "      <td>2319</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Change is</td>\n",
       "      <td>Everyday in everything and always. Change is a...</td>\n",
       "      <td>[Everyday in everything and, always Change, is...</td>\n",
       "      <td>[Undefined, A_def, P_bevb_x]</td>\n",
       "      <td>213</td>\n",
       "      <td>[0.14, 0.25, 0.25]</td>\n",
       "      <td>[0.56, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2197.17</td>\n",
       "      <td>2197</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>When they avoided me</td>\n",
       "      <td>I saw it as an expression of form only, which ...</td>\n",
       "      <td>[I saw it as an expression of form, only which...</td>\n",
       "      <td>[A_def, P_bevb_x, P_bevb_x]</td>\n",
       "      <td>186</td>\n",
       "      <td>[0.22, 0.25, 0.25]</td>\n",
       "      <td>[0.88, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2612.25</td>\n",
       "      <td>2612</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>My main problem is</td>\n",
       "      <td>being in my head rather than fully present and...</td>\n",
       "      <td>[being in my head rather than fully present an...</td>\n",
       "      <td>[A_pron_x, A_def, P_bevb_x, A_def, A_def, P_be...</td>\n",
       "      <td>380</td>\n",
       "      <td>[0.14, 0.14, 0.25, 0.22, 0.14, 0.14, 0.25, 0.2...</td>\n",
       "      <td>[0.56, 0.56, 1.0, 0.88, 0.56, 0.56, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>3105.25</td>\n",
       "      <td>3105</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>My main problem is</td>\n",
       "      <td>saying no... because I want to be helpful... b...</td>\n",
       "      <td>[saying no, because I want to be helpful but, ...</td>\n",
       "      <td>[P_yn, P_bevb_x, P_bevb_x, P_get_x, A_def, A_def]</td>\n",
       "      <td>470</td>\n",
       "      <td>[0.14, 0.25, 0.22, 0.14, 0.14, 0.14]</td>\n",
       "      <td>[0.56, 1.0, 0.88, 0.56, 0.56, 0.56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2170.02</td>\n",
       "      <td>2170</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>When I am criticized</td>\n",
       "      <td>if I am depleted, I tend to take the criticism...</td>\n",
       "      <td>[if I am depleted, I tend to take the criticis...</td>\n",
       "      <td>[P_bevb_x, A_def, P_bevb_x, A_def, A_def, A_pr...</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.22, 0.25, 0.22, 0.22, 0.25, 0.22, 0.22, 0.2...</td>\n",
       "      <td>[0.88, 1.0, 0.88, 0.88, 1.0, 0.88, 0.88, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>2552.24</td>\n",
       "      <td>2552</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>If I had more money</td>\n",
       "      <td>I would spend it on cool stuff.</td>\n",
       "      <td>[I would spend it on cool stuff]</td>\n",
       "      <td>[P_bevb_x]</td>\n",
       "      <td>366</td>\n",
       "      <td>[0.25]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>3288.16</td>\n",
       "      <td>3288</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>I feel sorry</td>\n",
       "      <td>when I hurt others.</td>\n",
       "      <td>[when I hurt others]</td>\n",
       "      <td>[A_def]</td>\n",
       "      <td>530</td>\n",
       "      <td>[0.22]</td>\n",
       "      <td>[0.88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>3099.22</td>\n",
       "      <td>3099</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>At times I worry about</td>\n",
       "      <td>big, big existential questions, and little mic...</td>\n",
       "      <td>[big big existential questions and little micr...</td>\n",
       "      <td>[Undefined]</td>\n",
       "      <td>464</td>\n",
       "      <td>[0.25]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2499.11</td>\n",
       "      <td>2499</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>What I like to do best is</td>\n",
       "      <td>play and eat sugar.</td>\n",
       "      <td>[play and, eat sugar]</td>\n",
       "      <td>[A_def, A_def]</td>\n",
       "      <td>274</td>\n",
       "      <td>[0.14, 0.12]</td>\n",
       "      <td>[0.56, 0.48]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UID  survey_id  prompt_number  prompt_id  \\\n",
       "301  2508.27       2508             27         98   \n",
       "213  2319.03       2319              3          3   \n",
       "186  2197.17       2197             17         17   \n",
       "380  2612.25       2612             25         25   \n",
       "470  3105.25       3105             25         25   \n",
       "161  2170.02       2170              2          2   \n",
       "366  2552.24       2552             24         24   \n",
       "530  3288.16       3288             16         16   \n",
       "464  3099.22       3099             22         43   \n",
       "274  2499.11       2499             11         39   \n",
       "\n",
       "                            prompt  \\\n",
       "301  Children who step out of line   \n",
       "213                      Change is   \n",
       "186           When they avoided me   \n",
       "380             My main problem is   \n",
       "470             My main problem is   \n",
       "161           When I am criticized   \n",
       "366            If I had more money   \n",
       "530                   I feel sorry   \n",
       "464         At times I worry about   \n",
       "274      What I like to do best is   \n",
       "\n",
       "                                              response  \\\n",
       "301  I don't know what that means (when children do...   \n",
       "213  Everyday in everything and always. Change is a...   \n",
       "186  I saw it as an expression of form only, which ...   \n",
       "380  being in my head rather than fully present and...   \n",
       "470  saying no... because I want to be helpful... b...   \n",
       "161  if I am depleted, I tend to take the criticism...   \n",
       "366                    I would spend it on cool stuff.   \n",
       "530                                when I hurt others.   \n",
       "464  big, big existential questions, and little mic...   \n",
       "274                                play and eat sugar.   \n",
       "\n",
       "                                    clauses_text_final  \\\n",
       "301  [I don, t know, what that means, when children...   \n",
       "213  [Everyday in everything and, always Change, is...   \n",
       "186  [I saw it as an expression of form, only which...   \n",
       "380  [being in my head rather than fully present an...   \n",
       "470  [saying no, because I want to be helpful but, ...   \n",
       "161  [if I am depleted, I tend to take the criticis...   \n",
       "366                   [I would spend it on cool stuff]   \n",
       "530                               [when I hurt others]   \n",
       "464  [big big existential questions and little micr...   \n",
       "274                              [play and, eat sugar]   \n",
       "\n",
       "                                                 voice  idx  \\\n",
       "301  [P_bevb_x, A_def, A_def, P_bevb_x, A_def, P_be...  301   \n",
       "213                       [Undefined, A_def, P_bevb_x]  213   \n",
       "186                        [A_def, P_bevb_x, P_bevb_x]  186   \n",
       "380  [A_pron_x, A_def, P_bevb_x, A_def, A_def, P_be...  380   \n",
       "470  [P_yn, P_bevb_x, P_bevb_x, P_get_x, A_def, A_def]  470   \n",
       "161  [P_bevb_x, A_def, P_bevb_x, A_def, A_def, A_pr...  161   \n",
       "366                                         [P_bevb_x]  366   \n",
       "530                                            [A_def]  530   \n",
       "464                                        [Undefined]  464   \n",
       "274                                     [A_def, A_def]  274   \n",
       "\n",
       "                                     abstraction_score  \\\n",
       "301               [0.22, 0.14, 0.14, 0.25, 0.14, 0.25]   \n",
       "213                                 [0.14, 0.25, 0.25]   \n",
       "186                                 [0.22, 0.25, 0.25]   \n",
       "380  [0.14, 0.14, 0.25, 0.22, 0.14, 0.14, 0.25, 0.2...   \n",
       "470               [0.14, 0.25, 0.22, 0.14, 0.14, 0.14]   \n",
       "161  [0.22, 0.25, 0.22, 0.22, 0.25, 0.22, 0.22, 0.2...   \n",
       "366                                             [0.25]   \n",
       "530                                             [0.22]   \n",
       "464                                             [0.25]   \n",
       "274                                       [0.14, 0.12]   \n",
       "\n",
       "                          abstraction_score_normalized  \n",
       "301                 [0.88, 0.56, 0.56, 1.0, 0.56, 1.0]  \n",
       "213                                   [0.56, 1.0, 1.0]  \n",
       "186                                   [0.88, 1.0, 1.0]  \n",
       "380  [0.56, 0.56, 1.0, 0.88, 0.56, 0.56, 1.0, 1.0, ...  \n",
       "470                [0.56, 1.0, 0.88, 0.56, 0.56, 0.56]  \n",
       "161  [0.88, 1.0, 0.88, 0.88, 1.0, 0.88, 0.88, 1.0, ...  \n",
       "366                                              [1.0]  \n",
       "530                                             [0.88]  \n",
       "464                                              [1.0]  \n",
       "274                                       [0.56, 0.48]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./abstraction_scored.csv\")\n",
    "df.clauses_text_final = df.clauses_text_final.apply(eval)\n",
    "df.voice = df.voice.apply(eval)\n",
    "df.abstraction_score = df.abstraction_score.apply(eval)\n",
    "df.sample(frac = 1).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw values of reading ease and grading levels are computed. These are available via Textacy's TextStats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>prompt_number</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>clauses_text_final</th>\n",
       "      <th>voice</th>\n",
       "      <th>idx</th>\n",
       "      <th>abstraction_score</th>\n",
       "      <th>abstraction_score_normalized</th>\n",
       "      <th>grading_level</th>\n",
       "      <th>reading_ease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2690.28</td>\n",
       "      <td>2690</td>\n",
       "      <td>28</td>\n",
       "      <td>83</td>\n",
       "      <td>A teacher has the right to</td>\n",
       "      <td>I don't mean to be oppositional. . but this se...</td>\n",
       "      <td>[I don, t mean to be oppositional but, this se...</td>\n",
       "      <td>[P_bevb_x, P_bevb_x, A_def, P_bevb_x, P_bevb_x...</td>\n",
       "      <td>399</td>\n",
       "      <td>[0.22, 0.14, 0.25, 0.14, 0.25, 0.25, 0.22, 0.2...</td>\n",
       "      <td>[0.88, 0.56, 1.0, 0.56, 1.0, 1.0, 0.88, 0.88, ...</td>\n",
       "      <td>[-3.01, 6.42, 0.52, 0.72, 7.37, 2.88, 1.31, -1...</td>\n",
       "      <td>[120.21, 59.75, 102.05, 97.03, 54.7, 83.32, 90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>3181.23</td>\n",
       "      <td>3181</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>I am</td>\n",
       "      <td>the voice at the edge of hearing, the movement...</td>\n",
       "      <td>[the voice at the edge of, hearing the movemen...</td>\n",
       "      <td>[Undefined, A_def, A_def, A_def, P_bevb_x, P_b...</td>\n",
       "      <td>508</td>\n",
       "      <td>[0.25, 0.25, 0.14, 0.14, 0.25, 0.25, 0.22, 0.1...</td>\n",
       "      <td>[1.0, 1.0, 0.56, 0.56, 1.0, 1.0, 0.88, 0.56, 0...</td>\n",
       "      <td>[-1.45, 5.86, -3.01, 4.66, 3.84, 3.72, 0.52, 2...</td>\n",
       "      <td>[116.15, 72.62, 120.21, 90.13, 88.91, 88.0, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2849.22</td>\n",
       "      <td>2849</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>At times I worry about</td>\n",
       "      <td>the fact that I can be inadvertently overbearing</td>\n",
       "      <td>[the fact, that I can be inadvertently overbea...</td>\n",
       "      <td>[Undefined, P_bevb_x]</td>\n",
       "      <td>439</td>\n",
       "      <td>[0.25, 0.25]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[-3.01, 10.35]</td>\n",
       "      <td>[120.21, 31.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1806.23</td>\n",
       "      <td>1806</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>I am</td>\n",
       "      <td>amazed at how quickly the world gives way to t...</td>\n",
       "      <td>[amazed at, how quickly the world gives way to...</td>\n",
       "      <td>[Undefined, A_def]</td>\n",
       "      <td>41</td>\n",
       "      <td>[0.11, 0.25]</td>\n",
       "      <td>[0.44, 1.0]</td>\n",
       "      <td>[-3.01, 1.03]</td>\n",
       "      <td>[120.21, 103.7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2360.32</td>\n",
       "      <td>2360</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>If I can\\'t get what I want</td>\n",
       "      <td>it\\'s not for me.</td>\n",
       "      <td>[want, it s not for me]</td>\n",
       "      <td>[A_def, A_def]</td>\n",
       "      <td>240</td>\n",
       "      <td>[0.14, 0.14]</td>\n",
       "      <td>[0.56, 0.56]</td>\n",
       "      <td>[-3.4, -1.84]</td>\n",
       "      <td>[121.22, 117.16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2170.02</td>\n",
       "      <td>2170</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>When I am criticized</td>\n",
       "      <td>if I am depleted, I tend to take the criticism...</td>\n",
       "      <td>[if I am depleted, I tend to take the criticis...</td>\n",
       "      <td>[P_bevb_x, A_def, P_bevb_x, A_def, A_def, A_pr...</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.22, 0.25, 0.22, 0.22, 0.25, 0.22, 0.22, 0.2...</td>\n",
       "      <td>[0.88, 1.0, 0.88, 0.88, 1.0, 0.88, 0.88, 1.0, ...</td>\n",
       "      <td>[3.67, 3.65, -2.23, -3.01, 6.71, 1.03, 0.52, 7...</td>\n",
       "      <td>[75.88, 84.9, 118.18, 120.21, 61.24, 103.7, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2532.03</td>\n",
       "      <td>2532</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>Grandparents</td>\n",
       "      <td>are very nice.</td>\n",
       "      <td>[are very nice]</td>\n",
       "      <td>[P_bevb_x]</td>\n",
       "      <td>318</td>\n",
       "      <td>[0.25]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[-2.62]</td>\n",
       "      <td>[119.19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2628.14</td>\n",
       "      <td>2628</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>The past</td>\n",
       "      <td>seems like remembering a movie I once watched,...</td>\n",
       "      <td>[seems like, remembering a movie, I once watch...</td>\n",
       "      <td>[A_def, A_def, A_def, P_bevb_x, A_def, A_def, ...</td>\n",
       "      <td>388</td>\n",
       "      <td>[0.12, 0.14, 0.25, 0.25, 0.14, 0.14, 0.14]</td>\n",
       "      <td>[0.48, 0.56, 1.0, 1.0, 0.56, 0.56, 0.56]</td>\n",
       "      <td>[-3.01, 9.18, -2.23, 0.52, 5.24, 0.72, 2.88]</td>\n",
       "      <td>[120.21, 34.59, 118.18, 102.05, 66.4, 97.03, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>3105.25</td>\n",
       "      <td>3105</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>My main problem is</td>\n",
       "      <td>saying no... because I want to be helpful... b...</td>\n",
       "      <td>[saying no, because I want to be helpful but, ...</td>\n",
       "      <td>[P_yn, P_bevb_x, P_bevb_x, P_get_x, A_def, A_def]</td>\n",
       "      <td>470</td>\n",
       "      <td>[0.14, 0.25, 0.22, 0.14, 0.14, 0.14]</td>\n",
       "      <td>[0.56, 1.0, 0.88, 0.56, 0.56, 0.56]</td>\n",
       "      <td>[2.89, 2.31, 0.72, 13.11, -2.23, 0.52]</td>\n",
       "      <td>[77.91, 90.96, 97.03, 6.39, 118.18, 102.05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1880.36</td>\n",
       "      <td>1880</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>Sometimes I wish that</td>\n",
       "      <td>I could be younger and have done things differ...</td>\n",
       "      <td>[I could be younger and, have done things diff...</td>\n",
       "      <td>[P_bevb_x, P_bevb_x]</td>\n",
       "      <td>79</td>\n",
       "      <td>[0.25, 0.14]</td>\n",
       "      <td>[1.0, 0.56]</td>\n",
       "      <td>[-1.84, 6.62]</td>\n",
       "      <td>[117.16, 54.73]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UID  survey_id  prompt_number  prompt_id  \\\n",
       "399  2690.28       2690             28         83   \n",
       "508  3181.23       3181             23         23   \n",
       "439  2849.22       2849             22         43   \n",
       "41   1806.23       1806             23         23   \n",
       "240  2360.32       2360             32         32   \n",
       "161  2170.02       2170              2          2   \n",
       "318  2532.03       2532              3         91   \n",
       "388  2628.14       2628             14         14   \n",
       "470  3105.25       3105             25         25   \n",
       "79   1880.36       1880             36         48   \n",
       "\n",
       "                          prompt  \\\n",
       "399   A teacher has the right to   \n",
       "508                         I am   \n",
       "439       At times I worry about   \n",
       "41                          I am   \n",
       "240  If I can\\'t get what I want   \n",
       "161         When I am criticized   \n",
       "318                 Grandparents   \n",
       "388                     The past   \n",
       "470           My main problem is   \n",
       "79         Sometimes I wish that   \n",
       "\n",
       "                                              response  \\\n",
       "399  I don't mean to be oppositional. . but this se...   \n",
       "508  the voice at the edge of hearing, the movement...   \n",
       "439  the fact that I can be inadvertently overbearing    \n",
       "41   amazed at how quickly the world gives way to t...   \n",
       "240                                 it\\'s not for me.    \n",
       "161  if I am depleted, I tend to take the criticism...   \n",
       "318                                     are very nice.   \n",
       "388  seems like remembering a movie I once watched,...   \n",
       "470  saying no... because I want to be helpful... b...   \n",
       "79   I could be younger and have done things differ...   \n",
       "\n",
       "                                    clauses_text_final  \\\n",
       "399  [I don, t mean to be oppositional but, this se...   \n",
       "508  [the voice at the edge of, hearing the movemen...   \n",
       "439  [the fact, that I can be inadvertently overbea...   \n",
       "41   [amazed at, how quickly the world gives way to...   \n",
       "240                            [want, it s not for me]   \n",
       "161  [if I am depleted, I tend to take the criticis...   \n",
       "318                                    [are very nice]   \n",
       "388  [seems like, remembering a movie, I once watch...   \n",
       "470  [saying no, because I want to be helpful but, ...   \n",
       "79   [I could be younger and, have done things diff...   \n",
       "\n",
       "                                                 voice  idx  \\\n",
       "399  [P_bevb_x, P_bevb_x, A_def, P_bevb_x, P_bevb_x...  399   \n",
       "508  [Undefined, A_def, A_def, A_def, P_bevb_x, P_b...  508   \n",
       "439                              [Undefined, P_bevb_x]  439   \n",
       "41                                  [Undefined, A_def]   41   \n",
       "240                                     [A_def, A_def]  240   \n",
       "161  [P_bevb_x, A_def, P_bevb_x, A_def, A_def, A_pr...  161   \n",
       "318                                         [P_bevb_x]  318   \n",
       "388  [A_def, A_def, A_def, P_bevb_x, A_def, A_def, ...  388   \n",
       "470  [P_yn, P_bevb_x, P_bevb_x, P_get_x, A_def, A_def]  470   \n",
       "79                                [P_bevb_x, P_bevb_x]   79   \n",
       "\n",
       "                                     abstraction_score  \\\n",
       "399  [0.22, 0.14, 0.25, 0.14, 0.25, 0.25, 0.22, 0.2...   \n",
       "508  [0.25, 0.25, 0.14, 0.14, 0.25, 0.25, 0.22, 0.1...   \n",
       "439                                       [0.25, 0.25]   \n",
       "41                                        [0.11, 0.25]   \n",
       "240                                       [0.14, 0.14]   \n",
       "161  [0.22, 0.25, 0.22, 0.22, 0.25, 0.22, 0.22, 0.2...   \n",
       "318                                             [0.25]   \n",
       "388         [0.12, 0.14, 0.25, 0.25, 0.14, 0.14, 0.14]   \n",
       "470               [0.14, 0.25, 0.22, 0.14, 0.14, 0.14]   \n",
       "79                                        [0.25, 0.14]   \n",
       "\n",
       "                          abstraction_score_normalized  \\\n",
       "399  [0.88, 0.56, 1.0, 0.56, 1.0, 1.0, 0.88, 0.88, ...   \n",
       "508  [1.0, 1.0, 0.56, 0.56, 1.0, 1.0, 0.88, 0.56, 0...   \n",
       "439                                         [1.0, 1.0]   \n",
       "41                                         [0.44, 1.0]   \n",
       "240                                       [0.56, 0.56]   \n",
       "161  [0.88, 1.0, 0.88, 0.88, 1.0, 0.88, 0.88, 1.0, ...   \n",
       "318                                              [1.0]   \n",
       "388           [0.48, 0.56, 1.0, 1.0, 0.56, 0.56, 0.56]   \n",
       "470                [0.56, 1.0, 0.88, 0.56, 0.56, 0.56]   \n",
       "79                                         [1.0, 0.56]   \n",
       "\n",
       "                                         grading_level  \\\n",
       "399  [-3.01, 6.42, 0.52, 0.72, 7.37, 2.88, 1.31, -1...   \n",
       "508  [-1.45, 5.86, -3.01, 4.66, 3.84, 3.72, 0.52, 2...   \n",
       "439                                     [-3.01, 10.35]   \n",
       "41                                       [-3.01, 1.03]   \n",
       "240                                      [-3.4, -1.84]   \n",
       "161  [3.67, 3.65, -2.23, -3.01, 6.71, 1.03, 0.52, 7...   \n",
       "318                                            [-2.62]   \n",
       "388       [-3.01, 9.18, -2.23, 0.52, 5.24, 0.72, 2.88]   \n",
       "470             [2.89, 2.31, 0.72, 13.11, -2.23, 0.52]   \n",
       "79                                       [-1.84, 6.62]   \n",
       "\n",
       "                                          reading_ease  \n",
       "399  [120.21, 59.75, 102.05, 97.03, 54.7, 83.32, 90...  \n",
       "508  [116.15, 72.62, 120.21, 90.13, 88.91, 88.0, 10...  \n",
       "439                                    [120.21, 31.55]  \n",
       "41                                     [120.21, 103.7]  \n",
       "240                                   [121.22, 117.16]  \n",
       "161  [75.88, 84.9, 118.18, 120.21, 61.24, 103.7, 10...  \n",
       "318                                           [119.19]  \n",
       "388  [120.21, 34.59, 118.18, 102.05, 66.4, 97.03, 8...  \n",
       "470        [77.91, 90.96, 97.03, 6.39, 118.18, 102.05]  \n",
       "79                                     [117.16, 54.73]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_readability(text):\n",
    "    doc = textacy.Doc(text, lang = \"en\")\n",
    "    ts = TextStats(doc)\n",
    "    return ts.readability_stats\n",
    "\n",
    "df['readability_attributes_score'] = df.clauses_text_final.apply(lambda arr: [score_readability(x) for x in arr])\n",
    "df['grading_level'] = df.readability_attributes_score.apply(lambda dct_arr: [round(dct['flesch_kincaid_grade_level'], 2) for dct in dct_arr])\n",
    "df['reading_ease'] = df.readability_attributes_score.apply(lambda dct_arr: [round(dct['flesch_reading_ease'], 2) for dct in dct_arr])\n",
    "_ = \"\"\"[{'flesch_kincaid_grade_level': 0.6257142857142846, 'flesch_reading_ease': 103.04428571428573, 'smog_index': 3.1291, 'gunning_fog_index': 2.8000000000000003, 'coleman_liau_index': 2.6518669999999993, 'automated_readability_index': 0.23714285714285666, 'lix': 7.0, 'gulpease_index': 93.28571428571428, 'wiener_sachtextformel': -2.5074571428571426}]\"\"\"\n",
    "del df['readability_attributes_score']\n",
    "df.sample(frac = 1).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The absolute metrics are normalized between a 0-1 scale. The reading ease is inversely proportional to the quality of the sentence. So the reading-ease values are negated and these negated scores are reverse normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>prompt_number</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>clauses_text_final</th>\n",
       "      <th>voice</th>\n",
       "      <th>idx</th>\n",
       "      <th>abstraction_score</th>\n",
       "      <th>abstraction_score_normalized</th>\n",
       "      <th>grading_level</th>\n",
       "      <th>reading_ease</th>\n",
       "      <th>reading_ease_normalized</th>\n",
       "      <th>grading_level_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2952.25</td>\n",
       "      <td>2952</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>My main problem is</td>\n",
       "      <td>getting over decades spent proving myself.</td>\n",
       "      <td>[getting over decades, spent proving myself]</td>\n",
       "      <td>[A_def, A_def]</td>\n",
       "      <td>462</td>\n",
       "      <td>[0.25, 0.14]</td>\n",
       "      <td>[1.0, 0.56]</td>\n",
       "      <td>[1.31, 5.25]</td>\n",
       "      <td>[90.99, 62.79]</td>\n",
       "      <td>[0.09, 0.17]</td>\n",
       "      <td>[0.1, 0.18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2296.34</td>\n",
       "      <td>2296</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>Technology</td>\n",
       "      <td>is simply a tool.</td>\n",
       "      <td>[is simply a tool]</td>\n",
       "      <td>[P_bevb_x]</td>\n",
       "      <td>206</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.72]</td>\n",
       "      <td>[97.03]</td>\n",
       "      <td>[0.07]</td>\n",
       "      <td>[0.09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2249.24</td>\n",
       "      <td>2249</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>If I had more money</td>\n",
       "      <td>I would save and invest, hoard and spend frivo...</td>\n",
       "      <td>[I would save and, invest hoard and, spend fri...</td>\n",
       "      <td>[P_bevb_x, A_def, A_def, P_bevb_x, P_bevb_x, P...</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.22, 0.14, 0.14, 0.22, 0.22, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[0.88, 0.56, 0.56, 0.88, 0.88, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[-2.23, 1.31, 2.89, 0.52, 0.52, 10.21, 6.71, 1...</td>\n",
       "      <td>[118.18, 90.99, 77.91, 100.24, 100.24, 37.9, 6...</td>\n",
       "      <td>[0.01, 0.09, 0.13, 0.06, 0.06, 0.25, 0.18, 0.33]</td>\n",
       "      <td>[0.02, 0.1, 0.13, 0.08, 0.08, 0.29, 0.21, 0.37]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2618.12</td>\n",
       "      <td>2618</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>A good boss</td>\n",
       "      <td>fosters the creativity of the team, both indiv...</td>\n",
       "      <td>[fosters the creativity of the team both indiv...</td>\n",
       "      <td>[A_def]</td>\n",
       "      <td>382</td>\n",
       "      <td>[0.25]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[14.27]</td>\n",
       "      <td>[10.57]</td>\n",
       "      <td>[0.33]</td>\n",
       "      <td>[0.37]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1665.02</td>\n",
       "      <td>1665</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>When I am criticized</td>\n",
       "      <td>I often find myself running through a microgen...</td>\n",
       "      <td>[I often find, myself running through a microg...</td>\n",
       "      <td>[A_def, A_def, A_def, A_def, A_def, A_def]</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.22, 0.25, 0.14, 0.25, 0.12, 0.25]</td>\n",
       "      <td>[0.88, 1.0, 0.56, 1.0, 0.48, 1.0]</td>\n",
       "      <td>[1.31, 8.9, 10.35, 14.65, -3.4, 7.63]</td>\n",
       "      <td>[90.99, 47.3, 31.55, 16.77, 121.22, 63.49]</td>\n",
       "      <td>[0.09, 0.22, 0.26, 0.31, 0.0, 0.17]</td>\n",
       "      <td>[0.1, 0.26, 0.29, 0.38, 0.0, 0.23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2025.22</td>\n",
       "      <td>2025</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>At times I worry about</td>\n",
       "      <td>I did not take fast action.</td>\n",
       "      <td>[I did not take fast action]</td>\n",
       "      <td>[P_bevb_x]</td>\n",
       "      <td>127</td>\n",
       "      <td>[0.25]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[0.52]</td>\n",
       "      <td>[102.05]</td>\n",
       "      <td>[0.06]</td>\n",
       "      <td>[0.08]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1831.11</td>\n",
       "      <td>1831</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>What I like to do best is</td>\n",
       "      <td>be in a complete experience of effortless flow...</td>\n",
       "      <td>[be in a complete experience of effortless flo...</td>\n",
       "      <td>[P_bevb_x]</td>\n",
       "      <td>60</td>\n",
       "      <td>[0.25]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[10.56]</td>\n",
       "      <td>[47.83]</td>\n",
       "      <td>[0.22]</td>\n",
       "      <td>[0.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2333.25</td>\n",
       "      <td>2333</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>My main problem is</td>\n",
       "      <td>I worry too much.</td>\n",
       "      <td>[I worry too much]</td>\n",
       "      <td>[A_def]</td>\n",
       "      <td>216</td>\n",
       "      <td>[0.25]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[0.72]</td>\n",
       "      <td>[97.03]</td>\n",
       "      <td>[0.07]</td>\n",
       "      <td>[0.09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2045.06</td>\n",
       "      <td>2045</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>The thing I like about myself is</td>\n",
       "      <td>I am adaptable and loving. I see people, natur...</td>\n",
       "      <td>[I am adaptable and, I see, people nature the ...</td>\n",
       "      <td>[P_bevb_x, A_def, A_def, P_bevb_x, A_def]</td>\n",
       "      <td>132</td>\n",
       "      <td>[0.22, 0.22, 0.14, 0.22, 0.22]</td>\n",
       "      <td>[0.88, 0.88, 0.56, 0.88, 0.88]</td>\n",
       "      <td>[0.72, -3.01, 4.0, 6.42, -1.06]</td>\n",
       "      <td>[97.03, 120.21, 78.87, 59.75, 115.13]</td>\n",
       "      <td>[0.07, 0.0, 0.13, 0.18, 0.02]</td>\n",
       "      <td>[0.09, 0.01, 0.16, 0.21, 0.05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1951.02</td>\n",
       "      <td>1951</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>When I am criticized</td>\n",
       "      <td>$% Meh &amp;#x29;&amp;#x28;*^ Bah IO} Ouch @#$ HA! #*$...</td>\n",
       "      <td>[Dare, I judge, He split, differentiate Self, ...</td>\n",
       "      <td>[A_def, A_def, A_def, A_def, A_def, P_bevb_x, ...</td>\n",
       "      <td>103</td>\n",
       "      <td>[0.12, 0.22, 0.14, 0.2, 0.14, 0.22, 0.25]</td>\n",
       "      <td>[0.48, 0.88, 0.56, 0.8, 0.56, 0.88, 1.0]</td>\n",
       "      <td>[-3.4, -3.01, -3.01, 20.59, 3.76, -2.62, -3.01]</td>\n",
       "      <td>[121.22, 120.21, 120.21, -48.99, 82.39, 119.19...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.5, 0.11, 0.01, 0.0]</td>\n",
       "      <td>[0.0, 0.01, 0.01, 0.51, 0.15, 0.02, 0.01]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UID  survey_id  prompt_number  prompt_id  \\\n",
       "462  2952.25       2952             25         25   \n",
       "206  2296.34       2296             34         47   \n",
       "200  2249.24       2249             24         24   \n",
       "382  2618.12       2618             12         12   \n",
       "8    1665.02       1665              2          2   \n",
       "127  2025.22       2025             22         43   \n",
       "60   1831.11       1831             11         39   \n",
       "216  2333.25       2333             25         25   \n",
       "132  2045.06       2045              6          6   \n",
       "103  1951.02       1951              2          2   \n",
       "\n",
       "                               prompt  \\\n",
       "462                My main problem is   \n",
       "206                        Technology   \n",
       "200               If I had more money   \n",
       "382                       A good boss   \n",
       "8                When I am criticized   \n",
       "127            At times I worry about   \n",
       "60          What I like to do best is   \n",
       "216                My main problem is   \n",
       "132  The thing I like about myself is   \n",
       "103              When I am criticized   \n",
       "\n",
       "                                              response  \\\n",
       "462         getting over decades spent proving myself.   \n",
       "206                                  is simply a tool.   \n",
       "200  I would save and invest, hoard and spend frivo...   \n",
       "382  fosters the creativity of the team, both indiv...   \n",
       "8    I often find myself running through a microgen...   \n",
       "127                        I did not take fast action.   \n",
       "60   be in a complete experience of effortless flow...   \n",
       "216                                  I worry too much.   \n",
       "132  I am adaptable and loving. I see people, natur...   \n",
       "103  $% Meh &#x29;&#x28;*^ Bah IO} Ouch @#$ HA! #*$...   \n",
       "\n",
       "                                    clauses_text_final  \\\n",
       "462       [getting over decades, spent proving myself]   \n",
       "206                                 [is simply a tool]   \n",
       "200  [I would save and, invest hoard and, spend fri...   \n",
       "382  [fosters the creativity of the team both indiv...   \n",
       "8    [I often find, myself running through a microg...   \n",
       "127                       [I did not take fast action]   \n",
       "60   [be in a complete experience of effortless flo...   \n",
       "216                                 [I worry too much]   \n",
       "132  [I am adaptable and, I see, people nature the ...   \n",
       "103  [Dare, I judge, He split, differentiate Self, ...   \n",
       "\n",
       "                                                 voice  idx  \\\n",
       "462                                     [A_def, A_def]  462   \n",
       "206                                         [P_bevb_x]  206   \n",
       "200  [P_bevb_x, A_def, A_def, P_bevb_x, P_bevb_x, P...  200   \n",
       "382                                            [A_def]  382   \n",
       "8           [A_def, A_def, A_def, A_def, A_def, A_def]    8   \n",
       "127                                         [P_bevb_x]  127   \n",
       "60                                          [P_bevb_x]   60   \n",
       "216                                            [A_def]  216   \n",
       "132          [P_bevb_x, A_def, A_def, P_bevb_x, A_def]  132   \n",
       "103  [A_def, A_def, A_def, A_def, A_def, P_bevb_x, ...  103   \n",
       "\n",
       "                                    abstraction_score  \\\n",
       "462                                      [0.25, 0.14]   \n",
       "206                                               [0]   \n",
       "200  [0.22, 0.14, 0.14, 0.22, 0.22, 0.25, 0.25, 0.25]   \n",
       "382                                            [0.25]   \n",
       "8                [0.22, 0.25, 0.14, 0.25, 0.12, 0.25]   \n",
       "127                                            [0.25]   \n",
       "60                                             [0.25]   \n",
       "216                                            [0.25]   \n",
       "132                    [0.22, 0.22, 0.14, 0.22, 0.22]   \n",
       "103         [0.12, 0.22, 0.14, 0.2, 0.14, 0.22, 0.25]   \n",
       "\n",
       "                      abstraction_score_normalized  \\\n",
       "462                                    [1.0, 0.56]   \n",
       "206                                          [0.0]   \n",
       "200  [0.88, 0.56, 0.56, 0.88, 0.88, 1.0, 1.0, 1.0]   \n",
       "382                                          [1.0]   \n",
       "8                [0.88, 1.0, 0.56, 1.0, 0.48, 1.0]   \n",
       "127                                          [1.0]   \n",
       "60                                           [1.0]   \n",
       "216                                          [1.0]   \n",
       "132                 [0.88, 0.88, 0.56, 0.88, 0.88]   \n",
       "103       [0.48, 0.88, 0.56, 0.8, 0.56, 0.88, 1.0]   \n",
       "\n",
       "                                         grading_level  \\\n",
       "462                                       [1.31, 5.25]   \n",
       "206                                             [0.72]   \n",
       "200  [-2.23, 1.31, 2.89, 0.52, 0.52, 10.21, 6.71, 1...   \n",
       "382                                            [14.27]   \n",
       "8                [1.31, 8.9, 10.35, 14.65, -3.4, 7.63]   \n",
       "127                                             [0.52]   \n",
       "60                                             [10.56]   \n",
       "216                                             [0.72]   \n",
       "132                    [0.72, -3.01, 4.0, 6.42, -1.06]   \n",
       "103    [-3.4, -3.01, -3.01, 20.59, 3.76, -2.62, -3.01]   \n",
       "\n",
       "                                          reading_ease  \\\n",
       "462                                     [90.99, 62.79]   \n",
       "206                                            [97.03]   \n",
       "200  [118.18, 90.99, 77.91, 100.24, 100.24, 37.9, 6...   \n",
       "382                                            [10.57]   \n",
       "8           [90.99, 47.3, 31.55, 16.77, 121.22, 63.49]   \n",
       "127                                           [102.05]   \n",
       "60                                             [47.83]   \n",
       "216                                            [97.03]   \n",
       "132              [97.03, 120.21, 78.87, 59.75, 115.13]   \n",
       "103  [121.22, 120.21, 120.21, -48.99, 82.39, 119.19...   \n",
       "\n",
       "                              reading_ease_normalized  \\\n",
       "462                                      [0.09, 0.17]   \n",
       "206                                            [0.07]   \n",
       "200  [0.01, 0.09, 0.13, 0.06, 0.06, 0.25, 0.18, 0.33]   \n",
       "382                                            [0.33]   \n",
       "8                 [0.09, 0.22, 0.26, 0.31, 0.0, 0.17]   \n",
       "127                                            [0.06]   \n",
       "60                                             [0.22]   \n",
       "216                                            [0.07]   \n",
       "132                     [0.07, 0.0, 0.13, 0.18, 0.02]   \n",
       "103             [0.0, 0.0, 0.0, 0.5, 0.11, 0.01, 0.0]   \n",
       "\n",
       "                            grading_level_normalized  \n",
       "462                                      [0.1, 0.18]  \n",
       "206                                           [0.09]  \n",
       "200  [0.02, 0.1, 0.13, 0.08, 0.08, 0.29, 0.21, 0.37]  \n",
       "382                                           [0.37]  \n",
       "8                 [0.1, 0.26, 0.29, 0.38, 0.0, 0.23]  \n",
       "127                                           [0.08]  \n",
       "60                                             [0.3]  \n",
       "216                                           [0.09]  \n",
       "132                   [0.09, 0.01, 0.16, 0.21, 0.05]  \n",
       "103        [0.0, 0.01, 0.01, 0.51, 0.15, 0.02, 0.01]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(row, x_max, x_min, reverse_arr = False):\n",
    "    if not reverse_arr:\n",
    "        return [round((x - x_min)/(x_max - x_min), 2) for x in row]\n",
    "    return [round((-1*x - x_min)/(x_max - x_min), 2) for x in row]\n",
    "\n",
    "reading_ease = df['reading_ease'].tolist()\n",
    "reading_ease = [j for i in reading_ease for j in i]\n",
    "reading_ease = [-1*x for x in reading_ease]\n",
    "x_max, x_min = max(reading_ease), min(reading_ease)\n",
    "df['reading_ease_normalized'] = df['reading_ease'].apply(lambda arr : normalize(arr, x_max, x_min, reverse_arr = True))\n",
    "\n",
    "grading_levels = df['grading_level'].tolist()\n",
    "grading_levels = [j for i in grading_levels for j in i]\n",
    "x_max, x_min = max(grading_levels), min(grading_levels)\n",
    "df['grading_level_normalized'] = df['grading_level'].apply(lambda arr : normalize(arr, x_max, x_min, reverse_arr = False))\n",
    "df.sample(frac = 1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "#Cross verify that they are correct\n",
    "reading_ease = df['reading_ease_normalized'].tolist()\n",
    "reading_ease = [j for i in reading_ease for j in i]\n",
    "grade = df['grading_level_normalized'].tolist()\n",
    "grade = [j for i in grade for j in i]\n",
    "print(max(reading_ease), min(reading_ease), max(grade), min(grade))\n",
    "df[['UID', 'survey_id', 'prompt_number', 'prompt_id', \"prompt\", \"response\", \"clauses_text_final\", \"voice\", \"idx\", \"abstraction_score_normalized\", \"reading_ease_normalized\", \"grading_level_normalized\"]].to_csv(\"readability_scored.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Computing the clause's overall quality\n",
    "This part determines how each clause adds importance to the overall intent of the sentence. To do this we evaluate keyword tuples (Usually an n-gram adds more value when compated to an individual token) of the original sentence using an unsupervised keyword extraction technique like SGRank (elaborated here: http://www.aclweb.org/anthology/S15-1013). The clauses that contain the n-grams are assigned the score of the n-gram as determined by SG Rank. The quality metric per clause is then determined as Sum(Sgrank values of tuples)/Total tuples with values.\n",
    "\n",
    "This output is stored in \"keyterm_scored.csv\" which will be used to evaluate the final scores and voices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy.keyterms import sgrank\n",
    "df['nlp_doc'] = df.apply(lambda row : textacy.Doc(row['prompt'] + \" \" + row['response'], lang = \"en\"), axis = 1)\n",
    "df['sgrank'] = df['nlp_doc'].apply(lambda doc : sgrank(doc, n_keyterms = len(doc)))\n",
    "\n",
    "def get_normalized_importance(df):\n",
    "    clauses = df[\"clauses_text_final\"]\n",
    "    rank_tuples = dict(df['sgrank'])\n",
    "    ngram_keys = rank_tuples.keys()\n",
    "    op = []\n",
    "    for clause in clauses:\n",
    "        str_clause = \"\".join(clause)\n",
    "        denominator = 0\n",
    "        numerator = 0\n",
    "        for x in ngram_keys:\n",
    "            if x in str_clause:\n",
    "                numerator += rank_tuples[x]\n",
    "                denominator += 1\n",
    "        op.append(round(numerator / denominator, 2) if denominator > 0 else 0.0)\n",
    "    return op\n",
    "    \n",
    "df[\"sgrank_normalized\"] = df.apply(get_normalized_importance, axis = 1)\n",
    "df[['UID', 'survey_id', 'prompt_number', 'prompt_id', \"prompt\", \"response\", \"clauses_text_final\", \"voice\", \"idx\", \"abstraction_score_normalized\", \"reading_ease_normalized\", \"grading_level_normalized\", \"sgrank_normalized\"]].to_csv(\"keyterm_scored.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
