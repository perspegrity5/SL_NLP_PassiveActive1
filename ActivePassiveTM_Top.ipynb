{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and running of AP code base:\n",
    "From ML Python notes: see \"Current (AP project) startup\"\n",
    "\n",
    "see also folder: 'tm_AP_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/tmurray/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tmurray/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/tmurray/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cymem.cymem.Pool has the wrong size, try recompiling. Expected 64, got 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a8bea29ec387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# from voice_identifier.py  main:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy_classifiers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain_voice_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtmlise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mabstraction_scores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain_abstraction_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreadability_scorer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain_readability_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonFiles/GitHub/SL_NLP_PassiveActive1/spacy_classifiers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# coding: utf-8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0municode_literals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcli_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mglossary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexplain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mabout\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.7/site-packages/spacy/cli/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlink\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpackage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.7/site-packages/spacy/cli/download.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mujson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlink\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_messages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_package_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.7/site-packages/spacy/cli/link.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_messages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msymlink_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath2str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.7/site-packages/spacy/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.7/site-packages/thinc/neural/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.7/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmsgpack_numpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumpyOps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCupyOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.7/site-packages/thinc/neural/util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_literals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreshed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaps\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreshMap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcymem.pxd\u001b[0m in \u001b[0;36minit preshed.maps\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cymem.cymem.Pool has the wrong size, try recompiling. Expected 64, got 48"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import nltk; nltk.download('wordnet'); nltk.download('stopwords'); nltk.download('punkt')\n",
    "import globals as g # tjm\n",
    "\n",
    "# from voice_identifier.py  main:\n",
    "from spacy_classifiers import main_voice_classifier, htmlise\n",
    "from abstraction_scores import main_abstraction_scorer\n",
    "from readability_scorer import main_readability_scorer\n",
    "from final_output_nb import main_final_output_scorer\n",
    "#from spacy_classifiers_copy import main_voice_classifier2 # , temp1\n",
    "\n",
    "\n",
    "print('done') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models\n",
      "Index(['UID', 'prompt', 'response', 'score', 'PassAct', 'surv_ogive',\n",
      "       'survey_id', 'prompt_number', 'prompt_id'],\n",
      "      dtype='object')\n",
      "Is this 0? 0\n",
      "MVC: Index(['UID', 'survey_id', 'prompt_number', 'prompt_id', 'prompt', 'response',\n",
      "       'clauses_text_final', 'clauses_doc_final', 'voice', 'score', 'PassAct',\n",
      "       'file_loc'],\n",
      "      dtype='object')\n",
      "MAS: Index(['UID', 'survey_id', 'prompt_number', 'prompt_id', 'prompt', 'response',\n",
      "       'clauses_text_final', 'clauses_doc_final', 'voice', 'score', 'PassAct',\n",
      "       'file_loc', 'abstraction_score', 'abstraction_score_normalized'],\n",
      "      dtype='object')\n",
      "1.0 0.0 1.0 0.0\n",
      "MRS: Index(['UID', 'survey_id', 'prompt_number', 'prompt_id', 'prompt', 'response',\n",
      "       'clauses_text_final', 'clauses_doc_final', 'voice', 'score', 'PassAct',\n",
      "       'file_loc', 'abstraction_score', 'abstraction_score_normalized',\n",
      "       'grading_level', 'reading_ease', 'reading_ease_normalized',\n",
      "       'grading_level_normalized', 'textacy_doc', 'sgrank',\n",
      "       'sgrank_normalized'],\n",
      "      dtype='object')\n",
      "Is this an empty dataframe? Empty DataFrame\n",
      "Columns: [clauses_text_final_length, voice_length, abstraction_score_normalized_length, reading_ease_normalized_length, grading_level_normalized_length, sgrank_normalized_length, flag]\n",
      "Index: []\n",
      "MOS: done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "ip_file = 'input.csv'\n",
    "result_file = 'result.csv'\n",
    "debug_file =  'debug.csv'\n",
    "model_type =  'en_core_web_lg'\n",
    "DEBUG_ABSTRACTION_HIERARCHY = False \n",
    "WEIGHT_METRICS = True\n",
    "ignore_prompt = False  \n",
    "save_html = True # syntax graphs\n",
    "html_file_dir='html'\n",
    "\n",
    "df1 = main_voice_classifier(model_type, ip_file, ignore_prompt, save_html=save_html, file_dir=html_file_dir)\n",
    "print('MVC:', df1.columns) # see file \n",
    "df2 = main_abstraction_scorer(df1, DEBUG_ABSTRACTION_HIERARCHY = DEBUG_ABSTRACTION_HIERARCHY)\n",
    "print('MAS:', df2.columns) # see file \n",
    "df3 = main_readability_scorer(df2, model_type)\n",
    "print('MRS:', df3.columns) # see file \n",
    "df4 = main_final_output_scorer(df3, result_file, debug_file, WEIGHT_METRICS = WEIGHT_METRICS)\n",
    "print('MOS: done') # df4 returns nothing...\n",
    "\n",
    "# >> see final files:  result.csv, debug.csv, weighted_debug.csv, weighted_result.csv\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# read in all data for what comes next\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd  # pip install xlrd\n",
    "\n",
    "the_folder = '/Users/tmurray/Documents/---Work/--Projects-Topics/StageLens_Project/_StageLens_RESEARCH/rubrics_project/'\n",
    "#infiles\n",
    "datafilepath = the_folder + '1941surv_w_scores_8.18copy.xlsx'\n",
    "\n",
    "df_file = pd.read_excel(datafilepath, sheet_name=\"scores\" ) \n",
    "df_file = df_file.fillna(value=\"()\")\n",
    "#df_file[df_file.r_protocol_id==4] # limit to genergal protocol\n",
    "\n",
    "df_r_s = df_file.loc[:, ('c_clean_prompt','c_clean_response','c_score_clean_num','r_pasAct','r_surv_ogive','survey_id', 'prompt_number', 'prompt_id')]  # ('Response','scorex2')] # replaced all scorex2 with socre in file\n",
    "df_r_s.columns =  ['prompt','response','score','PassAct','survOgive','survey_id', 'prompt_number', 'prompt_id'] # also want to try grouping by r_pasAct; or compbine by surv_ogive\n",
    "df_r_s['UID'] = df_r_s.apply(lambda row: '{0:0{width}}'.format(row['survey_id'], width=5)+ '.' + '{0:0{width}}'.format(row['prompt_number'], width=3)+'.', axis=1)\n",
    "\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all -ing words in database\n",
    "import re\n",
    "\n",
    "inglist = []\n",
    "\n",
    "df1 = df_r_s # [1:100]\n",
    "\n",
    "for i,r in df1.iterrows():\n",
    "    for w in  re.findall(r'\\w+', r['response']):\n",
    "        if w[-3:] == \"ing\":\n",
    "            #print(w)\n",
    "            inglist = inglist + [w.lower()]\n",
    "inglist = list(set(inglist))\n",
    "inglist = sorted(inglist) # ,key=str.lower\n",
    "print(len(inglist))\n",
    "#print(inglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01649.029.01=Dies I will go to her funeral=A_pron_x',\n",
       " '01650.027.03=have all my admiration=A_pron_x',\n",
       " '01813.007.03=how alien my constructions are to them=A_pron_x',\n",
       " '01813.007.04=how backward they often consider my ideas=A_pron_x',\n",
       " '01816.008.01=my desire=Undefined',\n",
       " '01816.008.04=that it takes away from my enjoyment of or full immersion in something=A_pron_x',\n",
       " '01823.033.04=oh that is Jumping around how sweet in my own skin=A_pron_x',\n",
       " '01823.036.03=when I close my eyes to look life s movement=A_pron_x',\n",
       " '01825.006.03=Finding my voice=A_pron_x',\n",
       " '01825.006.04=my creative expression feels good=A_pron_x',\n",
       " '01869.011.03=appreciating the good things in my life Restorative activities=A_pron_x',\n",
       " '01880.033.02=lose many of my competencies=A_pron_x',\n",
       " '01880.033.04=my behavior becomes very awkward=A_pron_x',\n",
       " '01889.013.04=yet manifesting our utter uniqueness=A_pron_x',\n",
       " '01889.029.01=and father find their full divine embrace within me=A_pron_x',\n",
       " '02069.003.06=what changes I welcome into my life=A_pron_x',\n",
       " '02128.021.03=imposing their perspectives on others=A_pron_x',\n",
       " '02150.034.02=to witness in our world=A_pron_x',\n",
       " '02206.034.03=I kiss my children goodnight and=A_pron_x',\n",
       " '02249.033.05=if I were unaware of my own nervousness=A_pron_x',\n",
       " '02250.011.04=riding my bike or=A_pron_x',\n",
       " '02300.008.01=my mouth and sometimes my temper=Undefined',\n",
       " '02338.008.02=setting it all free in my love=A_pron_x',\n",
       " '02350.002.05=how my dad criticized us=A_pron_x',\n",
       " '02485.016.01=so many people will go their entire lives=A_pron_x',\n",
       " '02498.015.02=being in my room=A_pron_x',\n",
       " '02498.015.03=because my momie miss me=A_pron_x',\n",
       " '02500.031.02=playing on his phone=A_pron_x',\n",
       " '02502.029.01=tells me to clean up my room=A_pron_x',\n",
       " '02510.011.01=be with my friends and family=A_pron_x',\n",
       " '02510.033.01=my hands get shaky=A_pron_x',\n",
       " '02514.008.01=probably my dyslexia not=Undefined',\n",
       " '02532.008.01=when my little brother screams=A_pron_x',\n",
       " '02536.020.01=it is their birthday=A_pron_x',\n",
       " '02541.008.01=hitting my sister and brother=A_pron_x',\n",
       " '02545.016.01=for my sister=Undefined',\n",
       " '02545.016.03=I cut my head=A_pron_x',\n",
       " '02550.011.04=riding my bike scooter=A_pron_x',\n",
       " '02551.020.01=it is their birthday=A_pron_x',\n",
       " '02672.025.01=I am not patient enough with my kids=A_pron_x',\n",
       " '02704.012.05=I work for you my student or worker and your success or failure=A_pron_x',\n",
       " '02704.012.06=the boss is my responsibility=A_pron_x',\n",
       " '02721.006.03=my Being=A_pron_x',\n",
       " '02721.006.05=who are also my Self=A_pron_x',\n",
       " '02721.013.02=Everyone released their identification with the limited self=A_pron_x',\n",
       " '02721.026.01=i feel adrenaline through my human body and=A_pron_x',\n",
       " '02737.023.03=what the soft animal of my body loves=A_pron_x',\n",
       " '02781.024.01=I d take care of my family=A_pron_x',\n",
       " '02806.012.02=who is there by your side=A_pron_x',\n",
       " '02826.001.04=I enjoy doing with my wife=A_pron_x',\n",
       " '02871.016.04=my worst fear is being stuck in a set of circumstances beyond my control=A_pron_x',\n",
       " '03118.004.02=the distinction between work and any other part of my life is fanciful=A_pron_x',\n",
       " '03178.001.01=Need a lot of dedication devotion personal time and discipline Not in my priorities currently=A_pron_x',\n",
       " '03184.020.04=tell our stories about ourselves in a compley pattern of experience awareness conscisnous=A_pron_x',\n",
       " '03195.020.02=as our collective consciousness is evolving=A_pron_x',\n",
       " '03286.014.03=our minds have created from our education and experience one=A_pron_x',\n",
       " '03286.025.01=that I forget my True Nature and resort to illusory concepts of myself=A_pron_x',\n",
       " '03287.018.02=according to their realm=A_pron_x',\n",
       " '03287.021.01=act out my own faults especially without=A_pron_x',\n",
       " '03342.036.01=free of all my shadows and handicaps=Undefined',\n",
       " '03405.013.04=a world expressing her love for herself=A_pron_x',\n",
       " '03405.033.04=what expression of my self is scared and about what=A_pron_x',\n",
       " '03423.022.02=we are leaving for our children and their children=A_pron_x',\n",
       " '03441.022.01=my physical health or my income=Undefined',\n",
       " '03449.028.02=listen set boundaries around their time=A_pron_x',\n",
       " '03449.028.03=energy and attention change their mind and=A_pron_x',\n",
       " '03482.019.02=making inadequate responses to their situation=A_pron_x',\n",
       " '03482.035.02=admitted the shortcomings of my behavior=A_pron_x',\n",
       " '03482.035.05=if I have not been able to learn from my errors=A_pron_x',\n",
       " '03556.027.01=Get their place taken=A_pron_x']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to find clauses with specific words:\n",
    "\n",
    "pos_adjs =  ['my', 'your', 'his', 'her', 'our', 'your', 'their'] # 'its', (NOT 'her' noun)\n",
    "pos_pronouns = ['mine', 'yours', 'his', 'hers', 'ours', 'yours', 'theirs'] \n",
    "getwords =[\"get\", \"seem\", \"feel\", \"gets\", \"seems\", \"feels\", \"got\", \"seemed\", \"felt\"]\n",
    "\n",
    "lookfor = set(pos_adjs + pos_pronouns) # set(getwords) # set(pos_adjs + pos_pronouns)\n",
    "\n",
    "getrows = [] \n",
    "for i, r in df4.iterrows():\n",
    "    # c = 0\n",
    "    #print(i)\n",
    "    if not(r.clause_num == 0):\n",
    "        cl_set = set(r.clauses_text_final.split())\n",
    "        if (cl_set & lookfor): # intersect\n",
    "            getrows.append(str(i)+\"=\"+r.clauses_text_final+\"=\"+r.voice)  #\n",
    "\n",
    "getrows\n",
    "# copy paste output into excel file etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create original sample data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "the_folder = '/Users/tmurray/Documents/---Work/--Projects-Topics/StageLens_Project/_StageLens_RESEARCH/rubrics_project/'\n",
    "#infiles\n",
    "datafilepath = the_folder + '1941surv_w_scores_8.18copy.xlsx'\n",
    "\n",
    "df_file = pd.read_excel(datafilepath, sheet_name=\"scores\" ) \n",
    "df_file = df_file.fillna(value=\"()\")\n",
    "df_file[df_file.r_protocol_id==4] # limit to genergal protocol\n",
    "\n",
    "df_r_s = df_file.loc[:, ('c_clean_prompt','c_clean_response','c_score_clean_num','r_pasAct','r_surv_ogive','survey_id', 'prompt_number', 'prompt_id')]  # ('Response','scorex2')] # replaced all scorex2 with socre in file\n",
    "df_r_s.columns =  ['prompt','response','score','PassAct','survOgive','survey_id', 'prompt_number', 'prompt_id'] # also want to try grouping by r_pasAct; or compbine by surv_ogive\n",
    "df_r_s['UID'] = df_r_s.apply(lambda row: '{0:0{width}}'.format(row['survey_id'], width=5)+ '.' + '{0:0{width}}'.format(row['prompt_number'], width=3)+'.', axis=1)\n",
    "\n",
    "df_sample = df_r_s[[(len(x)<200 and len(x)>15) for x in df_r_s['response']]]\n",
    "df_sample = df_sample[[x !=1.0 for x in df_sample['score']]]  # remove 1.0\n",
    "\n",
    "sample_size = 20 # per level\n",
    "#df_sample.groupby('score').apply(lambda x: x.sample(min(len(x), sample_size))) # \n",
    "df_sampled = df_sample.groupby('score', group_keys=False).apply(lambda x: x.sample(n=sample_size, replace=False)) # , group_keys=False\n",
    "\n",
    "#output in the python directory **\n",
    "df_sampled.to_csv(\"input.csv\", index = False)\n",
    "\n",
    "df_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
